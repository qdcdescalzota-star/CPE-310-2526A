{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU7KqHAqqGIG9bumHxL7Fx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qdcdescalzota-star/CPE-310-2526A/blob/main/DESCALZOTA_Midterm_Lab_Assessment_Data_Wrangling_with_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.\n",
        "Read in the meteorite data from the Meteorite_Landings.csv file, rename the mass (g) column to mass, and drop all the latitude and longitude columns. Sort the result by mass in descending order."
      ],
      "metadata": {
        "id": "SdJ0akRcmifp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyh9p2HJjvGZ",
        "outputId": "c1acefe5-01e7-4ae8-aa6d-ef994c8dffd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  name     id nametype      recclass        mass   fall  \\\n",
            "16392             Hoba  11890    Valid     Iron, IVB  60000000.0  Found   \n",
            "5373         Cape York   5262    Valid   Iron, IIIAB  58200000.0  Found   \n",
            "5365   Campo del Cielo   5247    Valid  Iron, IAB-MG  50000000.0  Found   \n",
            "5370     Canyon Diablo   5257    Valid  Iron, IAB-MG  30000000.0  Found   \n",
            "3455           Armanty   2335    Valid    Iron, IIIE  28000000.0  Found   \n",
            "\n",
            "                         year             GeoLocation  \n",
            "16392  01/01/1920 12:00:00 AM   (-19.58333, 17.91667)  \n",
            "5373   01/01/1818 12:00:00 AM   (76.13333, -64.93333)  \n",
            "5365   12/22/1575 12:00:00 AM  (-27.46667, -60.58333)  \n",
            "5370   01/01/1891 12:00:00 AM     (35.05, -111.03333)  \n",
            "3455   01/01/1898 12:00:00 AM            (47.0, 88.0)  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "meteorites = pd.read_csv('Meteorite_Landings.csv')\n",
        "\n",
        "# Rename the 'mass (g)' column to 'mass'\n",
        "meteorites = meteorites.rename(columns={'mass (g)': 'mass'})\n",
        "\n",
        "# Drop latitude and longitude columns\n",
        "meteorites = meteorites.drop(columns=['reclat', 'reclong'], errors='ignore')\n",
        "\n",
        "# Sort by mass in descending order\n",
        "meteorites_sorted = meteorites.sort_values(by='mass', ascending=False)\n",
        "\n",
        "print(meteorites_sorted.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2.\n",
        "Using the meteorite data from the Meteorite_Landings.csv file, update the year column to only contain the year, convert it to a numeric data type, and create a new column indicating whether the meteorite was observed falling before 1970. Set the index to the id column and extract all the rows with IDs between 10,036 and 10,040 (inclusive) with loc[]."
      ],
      "metadata": {
        "id": "Y5ure0jnmnJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting only the year from the 'year' column\n",
        "meteorites['year'] = meteorites['year'].astype(str).str.slice(0, 4)\n",
        "\n",
        "# Convert to numeric\n",
        "meteorites['year'] = pd.to_numeric(meteorites['year'], errors='coerce')\n",
        "\n",
        "# New column for meteorites observed before 1970\n",
        "meteorites['before_1970'] = meteorites['year'] < 1970\n",
        "\n",
        "# Set 'id' as the index\n",
        "meteorites = meteorites.set_index('id').sort_index()\n",
        "\n",
        "# Extract rows with IDs between 10036 and 10040\n",
        "subset = meteorites.loc[10036:10040]\n",
        "print(subset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwN46WzykyGq",
        "outputId": "ef419052-78f2-4e16-f9b5-d0fc3eea00a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            name nametype         recclass      mass   fall  year  \\\n",
            "id                                                                  \n",
            "10036     Enigma    Valid               H4      94.0  Found   NaN   \n",
            "10037       Enon    Valid  Iron, ungrouped     763.0  Found   NaN   \n",
            "10038      Enshi    Valid               H5    8000.0   Fell   NaN   \n",
            "10039  Ensisheim    Valid              LL6  127000.0   Fell   NaN   \n",
            "\n",
            "                 GeoLocation  before_1970  \n",
            "id                                         \n",
            "10036  (31.33333, -82.31667)        False  \n",
            "10037     (39.86667, -83.95)        False  \n",
            "10038          (30.3, 109.5)        False  \n",
            "10039       (47.86667, 7.35)        False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3.\n",
        "A) Using the meteorite data from the Meteorite_Landings.csv file, create a pivot table that shows both the number of meteorites and the 95th percentile of meteorite mass for those that were found versus observed falling per year from 2005 through 2009 (inclusive). Hint: Be sure to convert the year column to a number as we did in the previous exercise.\n",
        "B) Using the meteorite data from the Meteorite_Landings.csv file, compare summary statistics of the mass column for the meteorites that were found versus observed falling."
      ],
      "metadata": {
        "id": "ixTfMkSvmqsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data between 2005 and 2009\n",
        "meteorites_filtered = meteorites[(meteorites['year'] >= 2005) & (meteorites['year'] <= 2009)]\n",
        "\n",
        "# pivot table\n",
        "pivot = pd.pivot_table(\n",
        "    meteorites_filtered,\n",
        "    values='mass',\n",
        "    index='year',\n",
        "    columns='fall',\n",
        "    aggfunc={'mass': ['count', lambda x: x.quantile(0.95)]}\n",
        ")\n",
        "\n",
        "print(pivot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi4O4CHQlhFN",
        "outputId": "2b704da4-84f0-41e5-c433-fdff030cb102"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summary = meteorites.groupby('fall')['mass'].describe()\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUk9nfKfmQym",
        "outputId": "f9e9c7f3-c650-4f68-ad8e-fc9cb58ef55c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         count          mean            std  min     25%     50%      75%  \\\n",
            "fall                                                                        \n",
            "Fell    1075.0  47070.715023  717067.125826  0.1  686.00  2800.0  10450.0   \n",
            "Found  44510.0  12461.922983  571105.752311  0.0    6.94    30.5    178.0   \n",
            "\n",
            "              max  \n",
            "fall               \n",
            "Fell   23000000.0  \n",
            "Found  60000000.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4.\n",
        "Using the taxi trip data in the 2019_Yellow_Taxi_Trip_Data.csv file, resample the data to an hourly frequency based on the drop-off time. Calculate the total trip_distance, fare_amount, tolls_amount, and tip_amount, then find the 5 hours with the most tips."
      ],
      "metadata": {
        "id": "a1Zo3fHKmwTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read taxi data\n",
        "taxi = pd.read_csv('2019_Yellow_Taxi_Trip_Data.csv', parse_dates=['tpep_dropoff_datetime'])\n",
        "\n",
        "# Resample by hour based on drop-off time\n",
        "taxi_hourly = (\n",
        "    taxi.resample('h', on='tpep_dropoff_datetime')\n",
        "        [['trip_distance', 'fare_amount', 'tolls_amount', 'tip_amount']]\n",
        "        .sum()\n",
        ")\n",
        "\n",
        "# Find top 5 hours with most tips\n",
        "top_tips = taxi_hourly.sort_values('tip_amount', ascending=False).head(5)\n",
        "print(top_tips)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asmYdXRPmWF7",
        "outputId": "aea87700-4325-46ad-ed82-28133920759c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       trip_distance  fare_amount  tolls_amount  tip_amount\n",
            "tpep_dropoff_datetime                                                      \n",
            "2019-10-23 16:00:00         10676.95     67797.76        699.04    12228.64\n",
            "2019-10-23 17:00:00         16052.83     70131.91       4044.04    12044.03\n",
            "2019-10-23 18:00:00          3104.56     11565.56       1454.67     1907.64\n",
            "2019-10-23 15:00:00            14.34       213.50          0.00       51.75\n",
            "2019-10-23 19:00:00            98.59       268.00         24.48       25.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lPt3qcxJmhj2"
      }
    }
  ]
}